{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width = 400, align = \"center\"></a>\n",
    "\n",
    "<h1 align=center><font size = 5> K-Nearest Neighbors Classification in R: Exercise </font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Balance Scale\n",
    "\n",
    "In this exercise, we will be using the <font color = \"green\">balance_scale.txt</font> data set. In this data set, each data point is classified as having the balance scale tip to the right, tip to the left, or be balanced. The variables of the data set are 'left weight', 'left distance', 'right weight', and 'right distance'. The class is determined by the greater of (right-distance x right-weight) and (left-distance x left-weight). However, if these values are equal, the data point is balanced.\n",
    "\n",
    "The objective of this exercise is to use the k-nearest neighbors algorithm to determine the classification of test data and to estimate using knn regression, the difference between the product of right-distance and right-weight, and the product of left-distance and left-weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a). Install the package\n",
    "\n",
    "We first install and load the libraries that will be used in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the packages 'class' and 'kknn' and load their libraries, which will be needed for their k-nearest neighbors algorithms\n",
    "install.packages(\"class\")\n",
    "install.packages(\"kknn\")\n",
    "library(class)\n",
    "library(kknn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b). Download the data set, load the data and view its structure\n",
    "\n",
    "We can use the download.file command to download the data set, <font color = \"green\">\"balance_scale.txt\"</font>, load the data using the read.csv command, and view its structure using the str command. We will also look at the first few lines of the data using the head command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and view its structure\n",
    "balance_scale <- read.csv(\"https://ibm.box.com/shared/static/684jzm7e6fbbssg87yc2v4dy53dgkdew.txt\", sep = \",\")\n",
    "str(balance_scale)\n",
    "\n",
    "# View the first few rows of the data using the head function\n",
    "# Note: The raw data does not contain any column names\n",
    "head(balance_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c). Clean the data\n",
    "Now we will clean the data by adding column names, as well new columns for the right and left products and their differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Answer Code ## \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#p1\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n",
    "</div>\n",
    "<div id=\"p1\" class=\"collapse\">\n",
    "```\n",
    "# Add column names\n",
    "colnames(balance_scale) <- c(\"Class_Name\",\"Left_Weight\", \"Left_Distance\", \"Right_Weight\", \"Right_Distance\")\n",
    "head(balance_scale)\n",
    "# Note: We do not need to standardize the data in this instance since the numerical data values lie on the same scale.\n",
    "# Calculate the products and differences\n",
    "Right_Product <- balance_scale[,4]*balance_scale[,5]\n",
    "Left_Product <- balance_scale[,2]*balance_scale[,3]\n",
    "Differences <- Right_Product-Left_Product\n",
    "# Add columns for Right_Product, Left_Product and Differences\n",
    "balance_scale$Right_Product <- Right_Product\n",
    "balance_scale$Left_Product <- Left_Product\n",
    "balance_scale$Differences <- Differences\n",
    "    \n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d). Separate the data into training and test groups\n",
    "Next we will split the data into two groups which will be used for training and testing respectively. To do this, we will create a vector of equal length to our data, with approximately 70% of the values in the vector being 1's and the remaining values being 2's. The order in which the values appear will be random and depending on the indices of the vector which correspond to the value of 1 will be used to select our training data, while the indices corresponding to 2 will be used to select our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Answer Code ## \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#p2\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n",
    "</div>\n",
    "<div id=\"p2\" class=\"collapse\">\n",
    "```\n",
    "# Use the sample function to create a vector of indices that will be used\n",
    "set.seed(1234)\n",
    "ind <- sample(2, nrow(balance_scale), replace=TRUE, prob=c(0.7, 0.3))\n",
    "\n",
    "\n",
    "# Create the training and test data from the dataset using ind\n",
    "bscale.train <- balance_scale[ind==1, 6:8]\n",
    "bscale.test <- balance_scale[ind==2, 6:8]\n",
    "\n",
    "\n",
    "\n",
    "# Create the target vectors for the training and test data from the dataset using ind\n",
    "bscale.trainLabels <- balance_scale[ind==1, 1]\n",
    "bscale.testLabels <- balance_scale[ind==2, 1]\n",
    "    \n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e). Implementation of k-nearest neighbors for classification\n",
    "Now we will use the knn algorithm from the 'class' package to perform our classification task. This will be done using the knn command to determine the class name (R,L,B) of our test data based on our training data and our choice of k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Answer Code ## \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#p3\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n",
    "</div>\n",
    "<div id=\"p3\" class=\"collapse\">\n",
    "```\n",
    "# Use the knn command to make predictions on the Class_Name of the test data\n",
    "knn_class <- knn(train = bscale.train, test = bscale.test, cl = bscale.trainLabels, k=3)\n",
    "\n",
    "# Find the number of incorrectly classified points\n",
    "correct <- which(knn_class == bscale.testLabels, arr.ind = TRUE)\n",
    "incorrect <- which(knn_class != bscale.testLabels, arr.ind = TRUE)\n",
    "cat(\"Number of incorrectly classified points:\",length(incorrect),\"\\n\")\n",
    "\n",
    "# Find the proportion of correctly classified points\n",
    "proportion_correct <- length(correct)/length(bscale.testLabels)\n",
    "cat(\"Proportion of correctly classified points\", proportion_correct,\"\\n\")\n",
    "    \n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f). K-nearest neighbors regression using the kknn command\n",
    "The idea of using regression is by far predicting the continious response variable, instead of class variables, here the method is similar to localized linear regressions a.k.a LOESS, technique used, where $k$ is equivalent to the spread of kernel function around the point. [Reference](http://127.0.0.1:44104/help/library/kknn/doc/paper399.pdf) is good starting point to know about this methodology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Answer Code ## \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#p4\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n",
    "</div>\n",
    "<div id=\"p4\" class=\"collapse\">\n",
    "```\n",
    "# Run the knn regression using the kknn command\n",
    "knn_reg <- kknn(formula = Differences ~ ., train=bscale.train, test=bscale.test, k=3)\n",
    "\n",
    "# Find the number of incorrectly classified points\n",
    "incorrect_reg <- which(knn_reg$fitted.values != bscale.test$Differences, arr.ind = TRUE)\n",
    "cat(\"Number of incorrectly classified points:\", length(incorrect_reg), \"\\n\");\n",
    "\n",
    "# Find the proportion of correctly classified points\n",
    "correct_reg <- which(knn_reg$fitted.values == bscale.test$Differences, arr.ind = TRUE)\n",
    "cat(\"Proportion of correctly classified points\", length(correct_reg)/length(bscale.test$Differences), \"\\n\")\n",
    "\n",
    "\n",
    "# Display the first few rows of the regression estimates of the differences and their true values\n",
    "head(cbind(knn_reg$fitted.values,bscale.test$Differences))\n",
    "    \n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also determine the optimal value of k using the train.kknn command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Answer Code ## \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#p5\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n",
    "</div>\n",
    "<div id=\"p5\" class=\"collapse\">\n",
    "```\n",
    "best_reg <- train.kknn(formula = Differences ~ ., data=bscale.train, kmax=8)\n",
    "best_reg$best.parameters  \n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicate that the best value for k, in terms of knn regression, is k=2. This value makes sense given that the k-nearest neighbors regression algorithm estimates the outcome using a weighted average of the k nearest neighbors, weighted by the inverse of their distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the knn regression again using the kknn command with k=2\n",
    "knn_reg2 <- kknn(formula = Differences ~ ., train=bscale.train, test=bscale.test, k=2)\n",
    "\n",
    "# Find the number of incorrectly classified points\n",
    "incorrect_reg2 <- which(knn_reg2$fitted.values != bscale.test$Differences, arr.ind = TRUE)\n",
    "cat(\"Number of incorrectly classified points:\", length(incorrect_reg2),\"\\n\")\n",
    "# Find the proportion of correctly classified points\n",
    "correct_reg2 <- which(knn_reg2$fitted.values == bscale.test$Differences, arr.ind = TRUE)\n",
    "cat(\"Proportion of correctly classified points\",length(correct_reg2)/length(bscale.test$Differences),\"\\n\")\n",
    "\n",
    "# Display the first few rows of the new regression estimates of the differences and their true values\n",
    "head(cbind(knn_reg2$fitted.values,bscale.test$Differences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the estimates of the regression using k = 2 are closer to the true values with almost double the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g). K-nearest neighbors classification using the kknn command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the kknn command for classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Answer Code ## \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#p6\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n",
    "</div>\n",
    "<div id=\"p6\" class=\"collapse\">\n",
    "```\n",
    "# The kknn function can also be used for classification\n",
    "knn_class2 <- kknn(formula = Class_Name ~ ., train=subset(balance_scale, select=c(Class_Name,Right_Product,Left_Product,Differences))[ind==1,], test=subset(balance_scale, select=c(Class_Name,Right_Product,Left_Product,Differences))[ind==2,], k=3)\n",
    "# Find the number of incorrectly classified points\n",
    "incorrect_class2 <- which(knn_class2$fitted.values != bscale.testLabels, arr.ind = TRUE)\n",
    "cat(\"Number of incorrectly classified points:\",length(incorrect_class2),\"\\n\")\n",
    "    \n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try finding the optimal value of k for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_class <- train.kknn(formula = Class_Name ~ ., data=subset(balance_scale, select=c(Class_Name,Right_Product,Left_Product,Differences))[ind==1,], kmax=8)\n",
    "best_class$best.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using k=1\n",
    "knn_class3 <- kknn(formula = Class_Name ~ ., train=subset(balance_scale, select=c(Class_Name,Right_Product,Left_Product,Differences))[ind==1,], test=subset(balance_scale, select=c(Class_Name,Right_Product,Left_Product,Differences))[ind==2,], k=1)\n",
    "# Find the number of incorrectly classified points\n",
    "incorrect_class3 <- which(knn_class3$fitted.values != bscale.testLabels, arr.ind = TRUE)\n",
    "cat(\"Number of incorrectly classified points:\", length(incorrect_class3),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of using k=1 are apparently similar to those of using k=3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Exercise 2: Second Language Immersion Schools in Canada (Classification)\n",
    "\n",
    "French immersion programs are designed for students who are not native French speakers or students who do not speak French at home. These programs provide instruction in the classroom entirely in French until the end of grade 3, although certain specialist subjects may be instructed in English. We are provided with a data set of Canadian schools offering French immersion programs (<font color = \"green\">\"Second_Language_Immersion_Schools_in_Canada.csv\"</font>), which contains information regarding these schools such as their names, provinces and coordinates.\n",
    "\n",
    "Suppose we would like to determine the province in which a certain school or other place of interest is located in Canada, given that we have the coordinates (latitude and longitude) of this place. We can do this by using the k-nearest neighbor algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a). Download the data set, load the data and view its structure\n",
    "\n",
    "We can use the download.file command to download the data set, <font color = \"green\">\"Second_Language_Immersion_Schools_in_Canada.csv\"</font>, load the data using the read.csv command, and view its structure using the str command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data and view the structure\n",
    "schools <- read.csv(\"https://ibm.box.com/shared/static/uummw8ijp41gn3nfkuipi78xnalkss4c.csv\", sep = \",\")\n",
    "str(schools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b). Clean the data\n",
    "For the task we would like to do we only need a few variables of the data. These variables are school name (just for viewing), province, latitude and longitude. We will also change the variable names to cleaner names where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the data containing the variables province, latitude, and longitude\n",
    "schools.sub <- subset(schools, select=c(name, province.name..english, latitude, longitude))\n",
    "head(schools.sub)\n",
    "# Change the column names to cleaner names\n",
    "colnames(schools.sub) <- c(\"name\", \"province\", \"latitude\", \"longitude\")\n",
    "head(schools.sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c). Visualize the data on a map\n",
    "We will now install and load packages that will enable us to visualize our data by displayiing it on a map. This should make it easier to see clearly the predictions made by the knn algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing leaflet maps\n",
    "install.packages(\"leaflet\")\n",
    "library(leaflet)\n",
    "# Packages used to display the maps in this notebook\n",
    "library(htmlwidgets)\n",
    "library(IRdisplay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will set up a default parameters for the setView attribute of the map we are creating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Establish the limits of our default visualization\n",
    "lower_lon = -140\n",
    "upper_lon = -50\n",
    "lower_lat = 40\n",
    "upper_lat = 65\n",
    "# Establish the center of our default visualization\n",
    "center_lon = (lower_lon + upper_lon)/2\n",
    "center_lat = (lower_lat + upper_lat)/2\n",
    "# Set the zoom of our default visualization\n",
    "zoom = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create and display our map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a leaflet map\n",
    "schools_map <- leaflet(schools.sub) %>%\n",
    "  setView(center_lon,center_lat, zoom)%>% \n",
    "  addProviderTiles(\"OpenStreetMap.BlackAndWhite\")%>% # set the map that we want to use as background\n",
    "  addCircleMarkers(lng = schools.sub$longitude, \n",
    "                   lat = schools.sub$latitude, \n",
    "                   popup = schools.sub$name, # pop-ups will show the name of school if you click on a data point\n",
    "                   fillColor = \"Black\", # colors of the markers will be black\n",
    "                   fillOpacity = 1, # the shapes will have maximum opacity\n",
    "                   radius = 4, # radius determine the size of each shape\n",
    "                   stroke = F) # no stroke will be drawn in each data point\n",
    "\n",
    "saveWidget(schools_map, file=\"schools_map.html\", selfcontained = F) #saving the leaflet map in html\n",
    "display_html(paste(\"<iframe src=' \", 'schools_map.html', \" ' width='100%' height='400'\",\"/>\")) #display the map !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d). Implementation of k-nearest neighbors\n",
    "Now we will use the knn algorithm from the 'class' package to perform our classification task. This will be done by first separating our data into training and test groups, selecting our k parameter value, and then using them to make predictions of the provinces of our test data using the knn command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Your Answer Code ## \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "<a href=\"#p8\" class=\"btn btn-default\" data-toggle=\"collapse\">Click here for the solution</a>\n",
    "</div>\n",
    "<div id=\"p8\" class=\"collapse\">\n",
    "```\n",
    "# Use the sample function to create a vector of indices that will be used to split our data into training and test data\n",
    "set.seed(1234)\n",
    "ind <- sample(2, nrow(schools.sub), replace=TRUE, prob=c(0.7, 0.3)) # This creates a vector of equal length to our data, with approximately 70% of the values being 1 and the remaining values are 2  \n",
    "# Create training and test sets containing only the geographical locations \n",
    "schools.train <- schools.sub[ind==1,3:4]\n",
    "schools.test <- schools.sub[ind==2,3:4]\n",
    "# Note: Normalizing or standardizing the geographical attributes of the data will not be helpful since values are already on the same scale \n",
    "# Create the target vectors for the training and test data from the original dataset using ind\n",
    "schools.trainLabels <- schools.sub[ind==1,2]\n",
    "schools.testLabels <- schools.sub[ind==2,2]\n",
    "# Run the knn algorithm to classify test data points into the different provinces\n",
    "prov_pred <- knn(train = schools.train, test = schools.test, cl = schools.trainLabels, k=3)\n",
    "\n",
    "# Find the number of incorrectly classified points\n",
    "correct_provinces <- which(prov_pred == schools.testLabels, arr.ind = TRUE)\n",
    "incorrect_provinces <- which(prov_pred != schools.testLabels, arr.ind = TRUE)\n",
    "cat(\"Number of incorrectly classified points:\", length(incorrect_provinces),\"\\n\")\n",
    "# Find the proportion of correctly classified points\n",
    "proportion_of_correct_provinces <- length(correct_provinces)/length(schools.testLabels)\n",
    "cat(\"Proportion of correctly classified points\", proportion_of_correct_provinces,\"\\n\")\n",
    "    \n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e). Plot the classification predictions of k-nearest neighbors\n",
    "Now we will link the knn predictions of the provinces with the coordinates of the test data, and display them on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Link the knn predictions with the test data\n",
    "schools.test$prov <- prov_pred\n",
    "# Plot the test data with predicted provinces\n",
    "color <- colorFactor(topo.colors(10), schools.test$prov)\n",
    "schools_map2 <- leaflet(schools.test) %>%\n",
    "  setView(center_lon,center_lat, zoom)%>% \n",
    "  addProviderTiles(\"OpenStreetMap.BlackAndWhite\")%>% # set the map that we want to use as background\n",
    "  addCircleMarkers(lng = schools.test$longitude, \n",
    "                   lat = schools.test$latitude, \n",
    "                   popup = schools.test$prov, # pop-ups will show the predicted province if you click on a data point\n",
    "                   fillColor = ~color(prov),\n",
    "                   fillOpacity = 1, # the shapes will have maximum opacity\n",
    "                   radius = 4, # radius determine the size of each shape\n",
    "                   stroke = F) # no stroke will be drawn in each data point\n",
    "\n",
    "saveWidget(schools_map2, file=\"schools_map2.html\", selfcontained = F) #saving the leaflet map in html\n",
    "display_html(paste(\"<iframe src=' \", 'schools_map2.html', \" ' width='100%' height='400'\",\"/>\")) #display the map !\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?\n",
    "\n",
    "IBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems – by your enterprise as a whole. A free trial is available through this course, available here: [SPSS Modeler for Mac users](https://cocl.us/ML0151EN_SPSSMod_mac) and [SPSS Modeler for Windows users](https://cocl.us/ML0151EN_SPSSMod_win)\n",
    "\n",
    "Also, you can use Data Science Experience to run these notebooks faster with bigger datasets. Data Science Experience is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, DSX enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of DSX users today with a free account at [Data Science Experience](https://cocl.us/ML0151EN_DSX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank you for completing this exercise!\n",
    "\n",
    "Notebook created by: Dominique Warren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "* [K-Nearest Neighbors Algorithm (Wikipedia)](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    "* [K-Nearest Neighbors (Statsoft)](http://www.statsoft.com/textbook/k-nearest-neighbors)\n",
    "* [Information regarding the kknn package (CRAN)](https://cran.r-project.org/web/packages/kknn/kknn.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright &copy; 2017 [IBM Cognitive Class](https://cognitiveclass.ai/?utm_source=ML0151&utm_medium=lab&utm_campaign=cclab). This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
