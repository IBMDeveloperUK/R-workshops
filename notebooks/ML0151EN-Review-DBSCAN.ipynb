{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.bigdatauniversity.com\"><img src = \"https://ibm.box.com/shared/static/cw2c7r3o20w9zn8gkecaeyjhgw3xdgbj.png\" width = 400, align = \"center\"></a>\n",
    "\n",
    "<h1 align=center><font size = 5> DBSCAN Clustering in R</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "\n",
    "**Clustering**\n",
    "<ul>\n",
    "<li>The process of grouping similar objects together.\n",
    "<li>In other words clustering can be thought of as a **search of similarity**. <br>\n",
    "<img src=\"https://ibm.box.com/shared/static/g3vnplo98jckbievpulaet4qy7e0yxp5.png\" height=350 width=350>\n",
    "<br>\n",
    "One approach to this problem is to relate similarity with distance. Under this approach two items in a search space are similar to each other if the distance between them is small. One algorithm takes this approach is density-based approach. The density-based approach to clustering focus on identifying clusters of high density separated by areas of low density. It is particularly good for population-related geographical data because of its distribution nature. A popular and effective density-based algorithm, is **DBSCAN**, Density-based spatial clustering of application with noise.\n",
    "<br>. \n",
    "\n",
    "__What is DBSCAN?__  \n",
    "\n",
    "DBSCAN is one of the most common clustering algorithms and also most cited in scientific literature.\n",
    "Here’s a very simple way of understanding it: it clusters together neighbours. Or: Given a set of points in some space, it groups together points that are closely packed together (points with many nearby neighbors), marking as outliers points that lie alone in low-density regions regions (whose nearest neighbors are too far away). \n",
    "\n",
    "\n",
    "\n",
    "Some real-world applications of DBSCAN clustering:\n",
    "- Weather data clustering\n",
    "- Determining the best locations for service centres\n",
    "- Crime data clustering\n",
    "\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Table of contents \n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<font size = 3><strong>Density-based Clustering:</strong></font><br>\n",
    "- <p><a href=\"#ref1\">The problem we want to solve</a></p>\n",
    "- <p><a href=\"#ref2\">Framing the real problem to the application of DBSCAN</a></p>\n",
    "- <p><a href=\"#ref3\">The dataset</a></p>\n",
    "- <p><a href=\"#ref4\">A quick implementation</a></p>\n",
    "<p></p>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"ref1\"></a>\n",
    "# The problem to solve\n",
    "\n",
    "The year is 2036. You live in Canada and it is the end of the spring. The proportion of seniors aged 65 and over is <a href = http://www.statcan.gc.ca/pub/91-520-x/2010001/aftertoc-aprestdm1-eng.htm> 25% of the population</a>. While you are having your breakfast, an interview in the news channel draws your attention. The government of Canada is concerned with the upcoming heat waves in the summer, due to the particularly blistering hot temperatures in the last years. The Minister of Environment and Climate Change mentions during an interview that she is <font color = \"green\"> willing to create new weather stations. These stations will be packed with brand new equipment and will be responsible to collect information from collections of existing weather stations nearby, to better monitor the temperatures and prevent heat injuries in the increasingly older population. </font> As a person who cares about your future and your family's, you decide to help. You call a friend that works in the Institute of Weather Injuries  Prevention and he says that the government called two days ago asking him to **come up with the locations of the new weather stations. How many should be built, and where should each one be located?** In order to answer that question, your friend already assigned a research team to gather information on the existing weather stations. You will be responsible to process data that this research will generate. **Since you want to prepare the model before the data comes in, you will use a dataset about weather from 2015 to prepare all the code.**\n",
    "\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"ref2\"></a>\n",
    "# Framing the real problem\n",
    "\n",
    "First, let's give names to each type of station:\n",
    "- The *old station* will be called **\"normal station\" or \"old station\"**.\n",
    "- The *new station* will be called **\"main station\" or \"new station\"**.\n",
    "\n",
    "As mentioned before, DBSCAN focus on identifying clusters of high density separated by areas of low density. Since different types of distributions and densities are possible, each DBSCAN application **must be correctly tuned.**  \n",
    "  \n",
    "DBSCAN is an algorithm that must be tuned for each particular dataset, using the **eps** and **minPts** parameters. The \"eps\" corresponds to the **size of the neighborhood** and \"minPts\" to the **minimum number that must exist in this neighborhood to define it as a dense area**.  \n",
    "  \n",
    "To explain the meaning of each one of these parameters, we can use our example. We have our new weather stations that collect information of <font color = \"green\">collections of old weather stations</font>. In order to collect this type of information, a communication must be established between the weather stations. But there are two main restrictions:\n",
    " - There is a <font color = \"green\">maximum distance between two weather stations</font>  determined by a special cable with a determined maximum length (We have to use *special cables* to transmit data faster). However, we can connect stations that are further than this maximum distance from the main stations by connecting to weather stations that are within the reach of the main stations, with unlimited number of connections. \n",
    " - Just to justify the connection of an old weather station to the main station (through direct or indirect connections), it has to have a <font color = \"green\">minimum number of \"reachable\" stations using the *special cable*</font> (Perhaps because the price to setup the device for streaming is high).\n",
    "   \n",
    "In the analogy above, the <font color = \"green\">maximum distance between two weather stations</font> corresponds to the **eps** and the <font color = \"green\">minimum number of \"reachable\" stations using the *special cable*</font> to the **minPts**.\n",
    "\n",
    "From the problem information we had to determine <font color = \"green\">the number of main weather stations </font> and <font color = \"green\">their locations</font>, which are the **the number of clusters** and **the cluster centroids**.\n",
    "\n",
    " \n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"ref3\"></a>\n",
    "<a id=\"ref20\"></a>\n",
    "\n",
    "# The dataset\n",
    "As we mentioned before, the dataset used is from 2015. It contains information about a set of weather stations, with their respective names and geographical coordinates.\n",
    "\n",
    "Now let's start playing with the data. We will be working according to the following workflow: </font>\n",
    "1. Load\n",
    "- Overview\n",
    "- Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "<font size = 3><strong>Expert tip:</strong></font>\n",
    "<br>\n",
    "<br>\n",
    "We will go through these steps very quickly. If you want a better explanation of the process of managing datasets, you can check the <u>Introduction to R</u> course.<p></p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 1. Loading the data\n",
    "Since the dataset was uploaded to a Box folder, we can use the ***download.file*** command to download the dataset, and load the data using the ***read.csv*** command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Downloading the file in the Data Scientist Workbench\n",
    "download.file(\"https://ibm.box.com/shared/static/th5dsj5txtw052dt2k9i5hekkjhydda2.csv\",\"/resources/WeatherStations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Reading the csv file\n",
    "WeatherStations <- read.csv(\"/resources/WeatherStations.csv\", sep =',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 2. Overview of the data\n",
    "In this section, we will take a quick look in the data before processing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What does the data look like?\n",
    "head(WeatherStations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's check general information about the data!\n",
    "str(WeatherStations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "If you never worked with this dataset before, it might look very confusing! All the names are abbreviated and there is no way to know what each column means. To solve this problem, **we can simply look in the information given about the dataset.**\n",
    "\n",
    "In this notebook, we will be using only the columns with names listed in <font color = \"green\">green</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h3 align = \"center\">\n",
    "About the dataset\n",
    "</h3>\n",
    "<h4 align = \"center\">\n",
    "Environment Canada    \n",
    "Monthly Values for July - 2015\t\n",
    "</h4>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "table {\n",
    "    font-family: arial, sans-serif;\n",
    "    border-collapse: collapse;\n",
    "    width: 100%;\n",
    "}\n",
    "\n",
    "td, th {\n",
    "    border: 1px solid #dddddd;\n",
    "    text-align: left;\n",
    "    padding: 8px;\n",
    "}\n",
    "\n",
    "tr:nth-child(even) {\n",
    "    background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Name in the table</th>\n",
    "    <th>Meaning</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>Stn_Name</font></td>\n",
    "    <td><font color = \"green\"><strong>Station Name</font</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>Lat</font></td>\n",
    "    <td><font color = \"green\"><strong>Latitude (North+, degrees)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>Long</font></td>\n",
    "    <td><font color = \"green\"><strong>Longitude (West - , degrees)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Prov</td>\n",
    "    <td>Province</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Tm</td>\n",
    "    <td>Mean Temperature (°C)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwTm</td>\n",
    "    <td>Days without Valid Mean Temperature</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>D</td>\n",
    "    <td>Mean Temperature difference from Normal (1981-2010) (°C)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>Tx</font></td>\n",
    "    <td><font color = \"green\"><strong>Highest Monthly Maximum Temperature (°C)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwTx</td>\n",
    "    <td>Days without Valid Maximum Temperature</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><font color = \"green\"><strong>Tn</font></td>\n",
    "    <td><font color = \"green\"><strong>Lowest Monthly Minimum Temperature (°C)</font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwTn</td>\n",
    "    <td>Days without Valid Minimum Temperature</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>S</td>\n",
    "    <td>Snowfall (cm)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwS</td>\n",
    "    <td>Days without Valid Snowfall</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>S%N</td>\n",
    "    <td>Percent of Normal (1981-2010) Snowfall</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>P</td>\n",
    "    <td>Total Precipitation (mm)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwP</td>\n",
    "    <td>Days without Valid Precipitation</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>P%N</td>\n",
    "    <td>Percent of Normal (1981-2010) Precipitation</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>S_G</td>\n",
    "    <td>Snow on the ground at the end of the month (cm)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Pd</td>\n",
    "    <td>Number of days with Precipitation 1.0 mm or more</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>BS</td>\n",
    "    <td>Bright Sunshine (hours)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DwBS</td>\n",
    "    <td>Days without Valid Bright Sunshine</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>BS%</td>\n",
    "    <td>Percent of Normal (1981-2010) Bright Sunshine</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>HDD</td>\n",
    "    <td>Degree Days below 18 °C</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>CDD</td>\n",
    "    <td>Degree Days above 18 °C</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Stn_No</td>\n",
    "    <td>Climate station identifier (first 3 digits indicate   drainage basin, last 4 characters are for sorting alphabetically).</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>NA</td>\n",
    "    <td>Not Available</td>\n",
    "  </tr>\n",
    "\n",
    "\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 3. Cleaning the data\n",
    "Since we want to simplify the work and come up with a mock-up of our final model, we will work only in the location and temperature of the stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Creating the main subset: It contains the Station Name, latitude, longitude, highest monthly and lowest monthly temperature\n",
    "WeatherStations.submain <- subset(WeatherStations, select = c(Stn_Name,Lat,Long,Tx,Tn))\n",
    "head(WeatherStations.submain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Changing column names to cleaner names\n",
    "colnames(WeatherStations.submain) <- c(\"Stn_Name\",\"Lat\", \"Long\", \"Tmax\", \"Tmin\")\n",
    "head(WeatherStations.submain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Removing all the rows that are incomplete (rows that contain at least a NA)\n",
    "WeatherStations.submain <- WeatherStations.submain[complete.cases(WeatherStations.submain),]\n",
    "head(WeatherStations.submain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# A general visualization of the data\n",
    "Dealing with big amounts of data can be really overwhelming. Data visualization helps us get a better sense of what data we are working with. For this, <a href=\"https://rstudio.github.io/leaflet/\">Leaflet for R</a> will be used for plotting on top of a copy of a world map:\n",
    "\n",
    "1. Installing the library\n",
    "- Setting up the visualization\n",
    "- Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "<font size = 3><strong>Expert tip:</strong></font>\n",
    "<br>\n",
    "<br>\n",
    "We will go through these steps very quickly. If you want a better explanation of the process of map visualization, you can check the <u>Map Visualization in R</u> course.<p></p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 1. Installing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Installing leaflet maps\n",
    "install.packages(\"leaflet\")\n",
    "library(leaflet)\n",
    "# Packages used to display the maps in this notebook\n",
    "library(htmlwidgets)\n",
    "library(IRdisplay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 2. Setting up the visualization\n",
    "We will set the visualization by assigning the ***setView*** attribute to the map. We just have to come up with a *center point* of our visualization (lat,long) and determine a *zoom* rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Establishing the limits of our default visualization\n",
    "lower_lon = -140\n",
    "upper_lon = -50\n",
    "lower_lat = 40\n",
    "upper_lat = 65\n",
    "# Establishing the center of our default visualization\n",
    "center_lon = (lower_lon + upper_lon)/2\n",
    "center_lat = (lower_lat + upper_lat)/2\n",
    "# Setting the default zoom of our default visualization\n",
    "zoom = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 3. Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "subset <- WeatherStations.submain #'subset' stores the subset we will be using for the leaflet map\n",
    "weather_map <- leaflet(subset) %>% #creating a leaflet map\n",
    "                setView(center_lon,center_lat, zoom)%>% #setting the default view for our map\n",
    "                addProviderTiles(\"OpenStreetMap.BlackAndWhite\")%>% #setting the map that we want to use as background\n",
    "                addCircleMarkers(lng = subset$Long, #the longitude is the longitude of our subset!\n",
    "                                 lat = subset$Lat, #the latitude is the latitude of our subset!\n",
    "                                 popup = subset$Stn_Name, #pop-ups will show the name of station if you click in a data point\n",
    "                                 fillColor = \"Black\", #colors of the markers will be black\n",
    "                                 fillOpacity = 1, #the shapes will have maximum opacity\n",
    "                                 radius = 4, #radius determine the size of each shape\n",
    "                                 stroke = F) #no stroke will be drawn in each data point\n",
    "\n",
    "saveWidget(weather_map, file=\"weather_map.html\", selfcontained = F) #saving the leaflet map in html\n",
    "display_html(paste(\"<iframe src=' \", 'weather_map.html', \" ' width='100%' height='400'\",\"/>\")) #displaying the map !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id=\"ref4\"></a>\n",
    "# A quick implementation\n",
    "\n",
    "1. Installing the library\n",
    "- Clustering by location\n",
    "    1. Preparing the data\n",
    "    - Running the algorithm\n",
    "    - Attaching the cluster information to the data\n",
    "    - Visualizing the results\n",
    "- Clustering by location and temperature\n",
    "    1. Preparing the data\n",
    "    - Running the algorithm\n",
    "    - Attaching the cluster information to the data\n",
    "    - Visualizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 1. Installing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# installing the library 'dbscan'\n",
    "install.packages(\"dbscan\", dependencies = TRUE)\n",
    "library('dbscan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 2. Clustering by location\n",
    "At first, it was decided that only the location would matter, since we only have constraints in terms of length of the cable and the way we can make the connections to reach further distances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#####  Preparing the data (Subsetting and Normalizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# creating a subset containing only the location information\n",
    "WeatherStations.sub1 <- subset(WeatherStations.submain, select = c(Lat,Long))\n",
    "\n",
    "# preparing the dataset for dbscan: center and scale.\n",
    "scaled_WS.sub1 <- scale(WeatherStations.sub1, center = TRUE, scale = TRUE)\n",
    "head(scaled_WS.sub1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#####  Running the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<font size = 3><strong>\"Tuning\" the algorithm</strong></font><br>\n",
    "<p>As mentioned above, DBSCAN is an algorithm that must be tuned for each particular dataset, using the **eps** and **minPts** parameters. The \"eps\" corresponds to the **size of the neighborhood** and \"minPts\" to the **minimum number that must exist in this neighborhood to define it as a dense area**.  </p>\n",
    "\n",
    "<p>In this implementation, **we gave the correct parameters for each one of the applications.** However, if you plan to apply this algorithm to your own problem, you will have to tune it by your own, according to the dataset you are using. </p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# assigning clusters for each\n",
    "clusters_assignments1 <- dbscan(scaled_WS.sub1, eps = 0.138, minPts = 12)\n",
    "clusters_assignments1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Attaching cluster assignment to each one of the datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# clusters must be converted to factor before plotting in different colors\n",
    "clusters_assignments1$cluster <- as.factor(clusters_assignments1$cluster)\n",
    "\n",
    "# linking the assigned cluster to each station\n",
    "WeatherStations.sub1$cluster_no <- clusters_assignments1$cluster\n",
    "head(WeatherStations.sub1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Calculating the centroids for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# function that calculates the centroid of a given cluster_no and dataframe\n",
    "cluster_centroid <- function(cluster_no, df){\n",
    "    cluster_df <- df[ which(df$cluster_no==cluster_no), ]\n",
    "    lat_mean <- mean(cluster_df[[\"Lat\"]])\n",
    "    long_mean <-  mean(cluster_df[[\"Long\"]])\n",
    "    return(c(lat_mean,long_mean))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# function that calculates all the centroids latitudes of a given dataframe\n",
    "all_lats_centroids <- function(df){\n",
    "    all_lats <- numeric ()\n",
    "    for (cluster in unique (df$cluster_no)){\n",
    "        all_lats[cluster] <- cluster_centroid (cluster,df) [1]\n",
    "    }\n",
    "    return (all_lats)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# function that calculates all the centroids longitudes of a given dataframe\n",
    "all_longs_centroids <- function(df){\n",
    "    all_longs <- numeric ()\n",
    "    for (cluster in unique (df$cluster_no)){\n",
    "        all_longs[cluster] <- cluster_centroid (cluster,df) [2]\n",
    "    }\n",
    "    return (all_longs)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# storing the latitude of all cluster centroids\n",
    "lats_centroids1 <- all_lats_centroids (WeatherStations.sub1)\n",
    "lats_centroids1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# storing the longitude of all cluster centroids\n",
    "longs_centroids1 <- all_longs_centroids (WeatherStations.sub1)\n",
    "longs_centroids1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Visualizing the results\n",
    "Note that cluster number **0 represents the noise points.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting the graph\n",
    "subset <- WeatherStations.sub1\n",
    "color <- colorFactor(\"Set1\", as.factor(subset$cluster_no))\n",
    "weather_map1 <- leaflet(subset) %>%\n",
    "                setView(center_lon,center_lat, zoom)%>% \n",
    "                addProviderTiles(\"OpenStreetMap.BlackAndWhite\")%>% \n",
    "                addCircleMarkers(lng = subset$Long,\n",
    "                                lat = subset$Lat, \n",
    "                                popup = subset$Stn_Name,\n",
    "                                fillColor = ~color(cluster_no),\n",
    "                                fillOpacity = 1,\n",
    "                                radius = 4,\n",
    "                                stroke = F) %>% \n",
    "                addMarkers(lng = longs_centroids1,\n",
    "                           lat = lats_centroids1,\n",
    "                           popup = unique(subset$cluster_no))%>% \n",
    "                addLegend(\"bottomleft\",\n",
    "                        pal = color,\n",
    "                        values = ~cluster_no,\n",
    "                        opacity = 1,\n",
    "                        title = \"Cluster\")\n",
    "\n",
    "saveWidget(weather_map1, file=\"weather_map1.html\", selfcontained = F)\n",
    "\n",
    "# Plotting our raw data points\n",
    "display_html(paste(\"<iframe src=' \", 'weather_map.html', \" ' width='100%' height='400'\",\"/>\")) \n",
    "\n",
    "# Plotting our data points clustered by location\n",
    "display_html(paste(\"<iframe src=' \", 'weather_map1.html', \" ' width='100%' height='400'\",\"/>\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The markers represents each **main station** and each cluster color the different groups of **normal stations** assigned to different main stations.   \n",
    "<font color = \"red\"> **Note that the cluster 0 is compounded by unassigned points. Therefore, its main station shouldn't be built.** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### 3. Clustering by location and temperature\n",
    "After discussing more about the problem, it was decided that would be interesting to assign weather stations clustered by temperature. This way, if a main station detect a dangerous change in temperature, it can quickly warn all of its assigned weather stations, without losing time to identify and analyzing different temperature patterns. For that, we will have to maintain the location in consideration, but also take the temperature into account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#####  Preparing the data (Subsetting and Normalizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# creating a subset containing only the location\n",
    "WeatherStations.sub2 <- subset(WeatherStations.submain, select = c(Lat,Long,Tmax,Tmin))\n",
    "\n",
    "# preparing the dataset for dbscan: center and scale.\n",
    "scaled_WS.sub2 <- scale(WeatherStations.sub2, center = TRUE, scale = TRUE)\n",
    "head(scaled_WS.sub2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#####  Running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# assigning clusters for each\n",
    "clusters_assignments2 <- dbscan(scaled_WS.sub2, eps = 0.27, minPts = 12)\n",
    "clusters_assignments2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Attaching cluster assignment to each one of the datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# clusters must be converted to factor before plotting in different colors\n",
    "clusters_assignments2$cluster <- as.factor(clusters_assignments2$cluster)\n",
    "# linking the assigned cluster to each station\n",
    "WeatherStations.sub2$cluster_no <- clusters_assignments2$cluster\n",
    "head(WeatherStations.sub2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Calculating the centroids for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# storing the latitude of all cluster centroids\n",
    "lats_centroids2 <- all_lats_centroids (WeatherStations.sub2)\n",
    "lats_centroids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# storing the longitude of all cluster centroids\n",
    "longs_centroids2 <- all_longs_centroids (WeatherStations.sub2)\n",
    "longs_centroids2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "##### Visualizing the results\n",
    "Note that cluster number **0 represents the noise points.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# plotting the graph\n",
    "subset <- WeatherStations.sub2\n",
    "color <- colorFactor(\"Set1\", as.factor(subset$cluster_no))\n",
    "weather_map2 <- leaflet(subset) %>%\n",
    "                setView(center_lon,center_lat, zoom)%>% \n",
    "                addProviderTiles(\"OpenStreetMap.BlackAndWhite\")%>% \n",
    "                addCircleMarkers(lng = subset$Long,\n",
    "                                lat = subset$Lat, \n",
    "                                popup = subset$Stn_Name,\n",
    "                                fillColor = ~color(cluster_no),\n",
    "                                fillOpacity = 1,\n",
    "                                radius = 4,\n",
    "                                stroke = F) %>%\n",
    "                addMarkers(lng = longs_centroids2,\n",
    "                           lat = lats_centroids2,\n",
    "                           popup = unique(subset$cluster_no)) %>%\n",
    "                addLegend(\"bottomleft\",\n",
    "                        pal = color,\n",
    "                        values = ~cluster_no,\n",
    "                        opacity = 1,\n",
    "                        title = \"Cluster\")\n",
    "\n",
    "saveWidget(weather_map2, file=\"weather_map2.html\", selfcontained = F)\n",
    "\n",
    "# Plotting our raw data points\n",
    "display_html(paste(\"<iframe src=' \", 'weather_map.html', \" ' width='100%' height='400'\",\"/>\"))\n",
    "\n",
    "# Plotting our data points clustered by temperature and location\n",
    "display_html(paste(\"<iframe src=' \", 'weather_map2.html', \" ' width='100%' height='400'\",\"/>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The markers represents each **main station** and each cluster color the different groups of **normal stations** assigned to different main stations.   \n",
    "<font color = \"red\"> **Note that the cluster 0 is compounded by unassigned points. Therefore, its main station shouldn't be built.** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Our model is ready! Once we have more data about other weather conditions and parameters we can further refine, come up with better ideas and come up an infinite amount of ways to cluster the weather stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "__DBSCAN vs Other clustering algorithms:__ \n",
    "\n",
    "why do we use DBSCAN? What are its advantages, and how exactly does that result in better data analysis?\n",
    "The biggest advantage is it accounts for noise, because it is able to categorize certain points as outliers, as opposed to assigning every point to a cluster, like K-means does.\n",
    "\n",
    "\n",
    "DBSCAN Advantages:\n",
    "- It accounts for noise\n",
    "- It can correctly cluster very oddly shaped data  \n",
    "\n",
    "DBSCAN Results:\n",
    "- It is more realistic\n",
    "- It is more accurate\n",
    "- It is closer to human-like / sight-based understanding of data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<div class=\"alert alert-success alertsuccess\" style=\"margin-top: 20px\">\n",
    "<font size = 3><strong>Expert tip:</strong></font>\n",
    "<br>\n",
    "<br>\n",
    "Now that you know how we applied the DBSCAN to a specific problem, it's time to think about what kind of problem you can solve with this new tool. You can start by searching about it in the internet, and use this notebook as a quick way to apply DBSCAN on these different problems.<p></p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?\n",
    "\n",
    "IBM SPSS Modeler is a comprehensive analytics platform that has many machine learning algorithms. It has been designed to bring predictive intelligence to decisions made by individuals, by groups, by systems – by your enterprise as a whole. A free trial is available through this course, available here: [SPSS Modeler for Mac users](https://cocl.us/ML0151EN_SPSSMod_mac) and [SPSS Modeler for Windows users](https://cocl.us/ML0151EN_SPSSMod_win)\n",
    "\n",
    "Also, you can use Data Science Experience to run these notebooks faster with bigger datasets. Data Science Experience is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, DSX enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of DSX users today with a free account at [Data Science Experience](https://cocl.us/ML0151EN_DSX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### References:\n",
    "\n",
    "https://en.wikipedia.org/wiki/DBSCAN <br>\n",
    "https://cran.r-project.org/web/packages/dbscan/dbscan.pdf <br>\n",
    "https://www.aaai.org/Papers/KDD/1996/KDD96-037.pdf <br>\n",
    "http://www.cse.buffalo.edu/~jing/cse601/fa12/materials/clustering_density.pdf <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Thanks for completing this lesson!\n",
    "\n",
    "Notebook created by: <a href = \"https://ca.linkedin.com/in/erich-natsubori-sato\">Erich Natsubori Sato</a> , <a href = \"https://ca.linkedin.com/in/saeedaghabozorgi\">Saeed Aghabozorgi</a>\n",
    "<hr>\n",
    "Copyright &copy; 2017 [IBM Cognitive Class](https://cognitiveclass.ai/?utm_source=ML0151&utm_medium=lab&utm_campaign=cclab). This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
